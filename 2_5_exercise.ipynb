{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.5 exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2GSCrUbs0g5wQDZhBQ8ux"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F2No21FJETNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9968bf-d096-4c70-d575-422663be9577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-nightly\n",
            "  Downloading https://github.com/mlc-ai/utils/releases/download/v0.9.dev0/mlc_ai_nightly-0.9.dev1664%2Bg1f3985de0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 43.3 MB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.7.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (5.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (5.4.8)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (21.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.21.6)\n",
            "Collecting synr==0.6.0\n",
            "  Downloading synr-0.6.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (4.4.2)\n",
            "Installing collected packages: synr, mlc-ai-nightly\n",
            "Successfully installed mlc-ai-nightly-0.9.dev1664+g1f3985de0 synr-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!python3 -m  pip install mlc-ai-nightly -f https://mlc.ai/wheels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import tir as T"
      ],
      "metadata": {
        "id": "kBZcT9LQFDMq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Broadcast Add"
      ],
      "metadata": {
        "id": "qMk80_aTFTYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init data\n",
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(4, 0, -1).reshape(4)\n",
        "\n",
        "# numpy version\n",
        "c_np = a + b\n",
        "c_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB2RZketGCPO",
        "outputId": "fa2c831b-aca5-48cb-c68f-fa4a1d2215dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  4,  4,  4],\n",
              "       [ 8,  8,  8,  8],\n",
              "       [12, 12, 12, 12],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# low-level numpy version\n",
        "def lnumpy_boardcast_add(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      c[i, j] = a[i, j] + b[j]\n",
        "\n",
        "c_lnumpy = np.empty((4, 4), dtype=np.int64)\n",
        "lnumpy_boardcast_add(a, b, c_lnumpy)\n",
        "c_lnumpy"
      ],
      "metadata": {
        "id": "KTA_vR_JG_hb",
        "outputId": "1265f074-acb2-4119-e3d4-04fe20dec16d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  4,  4,  4],\n",
              "       [ 8,  8,  8,  8],\n",
              "       [12, 12, 12, 12],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer[(4, 4), \"int64\"],\n",
        "      B: T.Buffer[(4,), \"int64\"],\n",
        "      C: T.Buffer[(4, 4), \"int64\"]):\n",
        "    T.func_attr({\"global_symbol\": \"add\", \"tir.noalias\": True})\n",
        "    # TODO\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vj]\n",
        "    \n",
        "\n",
        "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
      ],
      "metadata": {
        "id": "ufxNNkXSGLbG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: 2D Convolution"
      ],
      "metadata": {
        "id": "oqrFLBGAFXk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
        "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
        "data = np.arange(N*CI*H*W).reshape(N, CI, H, W)\n",
        "weight = np.arange(CO*CI*K*K).reshape(CO, CI, K, K)"
      ],
      "metadata": {
        "id": "SrBmCnaDFb84"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight.shape"
      ],
      "metadata": {
        "id": "f6mnRarbop0z",
        "outputId": "3312572b-d831-40e2-97dc-7f21bfe382e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1, 3, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch version\n",
        "import torch\n",
        "\n",
        "data_torch = torch.Tensor(data)\n",
        "weight_torch = torch.Tensor(weight)\n",
        "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
        "conv_torch = conv_torch.numpy().astype(np.int64)\n",
        "conv_torch"
      ],
      "metadata": {
        "id": "PqJKzvrZmWgF",
        "outputId": "fa88908e-c37d-4d52-ca45-84780f0b4527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 474,  510,  546,  582,  618,  654],\n",
              "         [ 762,  798,  834,  870,  906,  942],\n",
              "         [1050, 1086, 1122, 1158, 1194, 1230],\n",
              "         [1338, 1374, 1410, 1446, 1482, 1518],\n",
              "         [1626, 1662, 1698, 1734, 1770, 1806],\n",
              "         [1914, 1950, 1986, 2022, 2058, 2094]],\n",
              "\n",
              "        [[1203, 1320, 1437, 1554, 1671, 1788],\n",
              "         [2139, 2256, 2373, 2490, 2607, 2724],\n",
              "         [3075, 3192, 3309, 3426, 3543, 3660],\n",
              "         [4011, 4128, 4245, 4362, 4479, 4596],\n",
              "         [4947, 5064, 5181, 5298, 5415, 5532],\n",
              "         [5883, 6000, 6117, 6234, 6351, 6468]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "# use variable as parameter may cause unexpected bug by tvm, https://github.com/mlc-ai/mlc-zh/discussions/33\n",
        "class MyConv:\n",
        "  @T.prim_func\n",
        "  def conv(input_data: T.Buffer[(1, 1, 8, 8), \"int64\"],\n",
        "       weight: T.Buffer[(2, 1, 3, 3), \"int64\"],\n",
        "       conv: T.Buffer[(1, 2, 6, 6), \"int64\"]):\n",
        "    T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
        "    # TODO\n",
        "    for b, k, i, j, di, dj, q in T.grid(1, 2, 6, 6, 3, 3, 1):\n",
        "      with T.block(\"conv\"):\n",
        "        vb, vk, vi, vj, vdi, vdj, vq = T.axis.remap(\"SSSSRRR\", [b, k, i, j, di, dj, q])\n",
        "        with T.init():\n",
        "          conv[vb, vk, vi, vj] = T.int64(0)\n",
        "        conv[vb, vk, vi, vj] += input_data[vb, vq, vi + vdi, vj + vdj] * weight[vk, vq, vdi, vdj]\n",
        "\n",
        "          \n",
        "\n",
        "rt_lib = tvm.build(MyConv, target=\"llvm\")\n",
        "data_tvm = tvm.nd.array(data)\n",
        "weight_tvm = tvm.nd.array(weight)\n",
        "conv_tvm = tvm.nd.array(np.empty((N, CO, OUT_H, OUT_W), dtype=np.int64))\n",
        "rt_lib[\"conv\"](data_tvm, weight_tvm, conv_tvm)\n",
        "np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
      ],
      "metadata": {
        "id": "o6ge-AV9mZK4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3: Transform a batch matmul program"
      ],
      "metadata": {
        "id": "70882y6CFePP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lnumpy_mm_relu_v2(A: np.ndarray, B: np.ndarray, C: np.ndarray):\n",
        "    Y = np.empty((16, 128, 128), dtype=\"float32\")\n",
        "    for n in range(16):\n",
        "        for i in range(128):\n",
        "            for j in range(128):\n",
        "                for k in range(128):\n",
        "                    if k == 0:\n",
        "                        Y[n, i, j] = 0\n",
        "                    Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
        "    for n in range(16):\n",
        "        for i in range(128):\n",
        "            for j in range(128):\n",
        "                C[n, i, j] = max(Y[n, i, j], 0)"
      ],
      "metadata": {
        "id": "0TKUYmXOFhhh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = \"float32\"\n",
        "a = np.random.rand(16, 128, 128).astype(dtype)\n",
        "b = np.random.rand(16, 128, 128).astype(dtype)\n",
        "c = np.empty((16, 128, 128), dtype=dtype)\n",
        "lnumpy_mm_relu_v2(a, b, c)"
      ],
      "metadata": {
        "id": "X88FhIHFydbJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyBmmRelu:\n",
        "  @T.prim_func\n",
        "  def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"],\n",
        "         B: T.Buffer[(16, 128, 128), \"float32\"],\n",
        "         C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
        "    T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
        "    # TODO\n",
        "    Y = T.alloc_buffer((16, 128, 128), dtype=\"float32\")\n",
        "    for n, i, j, k in T.grid(16, 128, 128, 128):\n",
        "      with T.block(\"Y\"):\n",
        "        vn, vi, vj, vk = T.axis.remap(\"SSSR\", [n, i, j, k])\n",
        "        with T.init():\n",
        "          Y[vn, vi, vj] = T.float32(0)\n",
        "        Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
        "\n",
        "    for n, i, j in T.grid(16, 128, 128):\n",
        "      with T.block(\"C\"):\n",
        "        vn, vi, vj = T.axis.remap(\"SSS\", [n, i, j])\n",
        "        C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
        "\n",
        "\n",
        "# evaluate\n",
        "rt_lib = tvm.build(MyBmmRelu, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((16, 128, 128), dtype=\"float32\"))\n",
        "rt_lib[\"bmm_relu\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c, rtol=1e-5)"
      ],
      "metadata": {
        "id": "DVWTNMYwv3vt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sch = tvm.tir.Schedule(MyBmmRelu)\n",
        "# TODO: transformations\n",
        "# Hints: you can use\n",
        "# `IPython.display.Code(sch.mod.script(), language=\"python\")`\n",
        "# or `print(sch.mod.script())`\n",
        "# to show the current program at any time during the transformation.\n",
        "\n",
        "# Step 1. Get blocks\n",
        "Y = sch.get_block(\"Y\", func_name=\"bmm_relu\")\n",
        "\n",
        "# Step 2. Get loops\n",
        "b, i, j, k = sch.get_loops(Y)\n",
        "sch.parallel(b)\n",
        "\n",
        "# Step 3. Organize the loops\n",
        "j0, j1 = sch.split(j, [32, 4])\n",
        "k0, k1 = sch.split(k, [16, 8])\n",
        "# sch.reorder(...)\n",
        "sch.reorder(j0, k0, k1, j1)\n",
        "# sch.compute_at/reverse_compute_at(...)\n",
        "\n",
        "\n",
        "# Step 4. decompose reduction\n",
        "# Y_init = sch.decompose_reduction(Y, ...)\n",
        "# ...\n",
        "\n",
        "# # Step 5. vectorize / parallel / unroll\n",
        "# sch.vectorize(...)\n",
        "sch.parallel(b)\n",
        "# sch.unroll(...)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# C = sch.get_block(\"C\", func_name=\"bmm_relu\")\n",
        "\n",
        "# IPython.display.Code(sch.mod.script(), language=\"python\")\n",
        "print(sch.mod.script())"
      ],
      "metadata": {
        "id": "76V9PVGvwESI",
        "outputId": "fcdf314a-214c-42d5-883e-f55c0695f037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@tvm.script.ir_module\n",
            "class Module:\n",
            "    @tir.prim_func\n",
            "    def bmm_relu(A: tir.Buffer[(16, 128, 128), \"float32\"], B: tir.Buffer[(16, 128, 128), \"float32\"], C: tir.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
            "        # function attr dict\n",
            "        tir.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
            "        # body\n",
            "        # with tir.block(\"root\")\n",
            "        Y = tir.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
            "        for n in tir.parallel(16):\n",
            "            for i, j_0, k_0, k_1, j_1 in tir.grid(128, 32, 16, 8, 4):\n",
            "                with tir.block(\"Y\"):\n",
            "                    vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                    vj = tir.axis.spatial(128, j_0 * 4 + j_1)\n",
            "                    vk = tir.axis.reduce(128, k_0 * 8 + k_1)\n",
            "                    tir.reads(A[vn, vi, vk], B[vn, vk, vj])\n",
            "                    tir.writes(Y[vn, vi, vj])\n",
            "                    with tir.init():\n",
            "                        Y[vn, vi, vj] = tir.float32(0)\n",
            "                    Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
            "        for n, i, j in tir.grid(16, 128, 128):\n",
            "            with tir.block(\"C\"):\n",
            "                vn, vi, vj = tir.axis.remap(\"SSS\", [n, i, j])\n",
            "                tir.reads(Y[vn, vi, vj])\n",
            "                tir.writes(C[vn, vi, vj])\n",
            "                C[vn, vi, vj] = tir.max(Y[vn, vi, vj], tir.float32(0))\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = sch.get_block(\"C\", func_name=\"bmm_relu\")\n",
        "sch.reverse_compute_at(C, j0)\n",
        "print(sch.mod.script())"
      ],
      "metadata": {
        "id": "xf5vXQy064vI",
        "outputId": "a87757e5-2351-4432-fce3-e87e51a0025d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@tvm.script.ir_module\n",
            "class Module:\n",
            "    @tir.prim_func\n",
            "    def bmm_relu(A: tir.Buffer[(16, 128, 128), \"float32\"], B: tir.Buffer[(16, 128, 128), \"float32\"], C: tir.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
            "        # function attr dict\n",
            "        tir.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
            "        # body\n",
            "        # with tir.block(\"root\")\n",
            "        Y = tir.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
            "        for n in tir.parallel(16):\n",
            "            for i, j_0 in tir.grid(128, 32):\n",
            "                for k_0, k_1, j_1 in tir.grid(16, 8, 4):\n",
            "                    with tir.block(\"Y\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 4 + j_1)\n",
            "                        vk = tir.axis.reduce(128, k_0 * 8 + k_1)\n",
            "                        tir.reads(A[vn, vi, vk], B[vn, vk, vj])\n",
            "                        tir.writes(Y[vn, vi, vj])\n",
            "                        with tir.init():\n",
            "                            Y[vn, vi, vj] = tir.float32(0)\n",
            "                        Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
            "                for ax0 in tir.serial(4):\n",
            "                    with tir.block(\"C\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 4 + ax0)\n",
            "                        tir.reads(Y[vn, vi, vj])\n",
            "                        tir.writes(C[vn, vi, vj])\n",
            "                        C[vn, vi, vj] = tir.max(Y[vn, vi, vj], tir.float32(0))\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_init = sch.decompose_reduction(Y, k0)\n",
        "print(sch.mod.script())"
      ],
      "metadata": {
        "id": "x9XXg-fk7sV3",
        "outputId": "266d93f4-6cac-40d3-e0b2-e20483059c52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@tvm.script.ir_module\n",
            "class Module:\n",
            "    @tir.prim_func\n",
            "    def bmm_relu(A: tir.Buffer[(16, 128, 128), \"float32\"], B: tir.Buffer[(16, 128, 128), \"float32\"], C: tir.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
            "        # function attr dict\n",
            "        tir.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
            "        # body\n",
            "        # with tir.block(\"root\")\n",
            "        Y = tir.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
            "        for n in tir.parallel(16):\n",
            "            for i, j_0 in tir.grid(128, 32):\n",
            "                for j_1_init in tir.serial(4):\n",
            "                    with tir.block(\"Y_init\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 4 + j_1_init)\n",
            "                        tir.reads()\n",
            "                        tir.writes(Y[vn, vi, vj])\n",
            "                        Y[vn, vi, vj] = tir.float32(0)\n",
            "                for k_0, k_1, j_1 in tir.grid(16, 8, 4):\n",
            "                    with tir.block(\"Y_update\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 4 + j_1)\n",
            "                        vk = tir.axis.reduce(128, k_0 * 8 + k_1)\n",
            "                        tir.reads(Y[vn, vi, vj], A[vn, vi, vk], B[vn, vk, vj])\n",
            "                        tir.writes(Y[vn, vi, vj])\n",
            "                        Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
            "                for ax0 in tir.serial(4):\n",
            "                    with tir.block(\"C\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 4 + ax0)\n",
            "                        tir.reads(Y[vn, vi, vj])\n",
            "                        tir.writes(C[vn, vi, vj])\n",
            "                        C[vn, vi, vj] = tir.max(Y[vn, vi, vj], tir.float32(0))\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5. vectorize / parallel / unroll\n",
        "n, i, j_0, j_1_init = sch.get_loops(Y_init)\n",
        "sch.vectorize(j_1_init)\n",
        "\n",
        "n, i, j_0, i2_1 = sch.get_loops(C)\n",
        "sch.vectorize(i2_1)\n",
        "\n",
        "print(sch.mod.script())"
      ],
      "metadata": {
        "id": "ydTWiNo68HZL",
        "outputId": "9d98b365-cd65-4f81-93de-caecd480ef0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@tvm.script.ir_module\n",
            "class Module:\n",
            "    @tir.prim_func\n",
            "    def bmm_relu(A: tir.Buffer[(16, 128, 128), \"float32\"], B: tir.Buffer[(16, 128, 128), \"float32\"], C: tir.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
            "        # function attr dict\n",
            "        tir.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
            "        # body\n",
            "        # with tir.block(\"root\")\n",
            "        Y = tir.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
            "        for n in tir.parallel(16):\n",
            "            for i, j_0 in tir.grid(128, 32):\n",
            "                for j_1_init in tir.vectorized(4):\n",
            "                    with tir.block(\"Y_init\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 4 + j_1_init)\n",
            "                        tir.reads()\n",
            "                        tir.writes(Y[vn, vi, vj])\n",
            "                        Y[vn, vi, vj] = tir.float32(0)\n",
            "                for k_0, k_1, j_1 in tir.grid(16, 8, 4):\n",
            "                    with tir.block(\"Y_update\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 4 + j_1)\n",
            "                        vk = tir.axis.reduce(128, k_0 * 8 + k_1)\n",
            "                        tir.reads(Y[vn, vi, vj], A[vn, vi, vk], B[vn, vk, vj])\n",
            "                        tir.writes(Y[vn, vi, vj])\n",
            "                        Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
            "                for ax0 in tir.vectorized(4):\n",
            "                    with tir.block(\"C\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 4 + ax0)\n",
            "                        tir.reads(Y[vn, vi, vj])\n",
            "                        tir.writes(C[vn, vi, vj])\n",
            "                        C[vn, vi, vj] = tir.max(Y[vn, vi, vj], tir.float32(0))\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_Y_update = sch.get_block(\"Y_update\", func_name=\"bmm_relu\")\n",
        "n, i, j_0, k_0, k_1, j_1 = sch.get_loops(block_Y_update)\n",
        "sch.unroll(k_1)\n",
        "print(sch.mod.script())"
      ],
      "metadata": {
        "id": "jrei_Yno8eHI",
        "outputId": "b9d7a760-2db2-4d72-800b-ea53f5ddb68d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@tvm.script.ir_module\n",
            "class Module:\n",
            "    @tir.prim_func\n",
            "    def bmm_relu(A: tir.Buffer[(16, 128, 128), \"float32\"], B: tir.Buffer[(16, 128, 128), \"float32\"], C: tir.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
            "        # function attr dict\n",
            "        tir.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
            "        # body\n",
            "        # with tir.block(\"root\")\n",
            "        Y = tir.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
            "        for n in tir.parallel(16):\n",
            "            for i, j_0 in tir.grid(128, 32):\n",
            "                for j_1_init in tir.vectorized(4):\n",
            "                    with tir.block(\"Y_init\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 4 + j_1_init)\n",
            "                        tir.reads()\n",
            "                        tir.writes(Y[vn, vi, vj])\n",
            "                        Y[vn, vi, vj] = tir.float32(0)\n",
            "                for k_0 in tir.serial(16):\n",
            "                    for k_1 in tir.unroll(8):\n",
            "                        for j_1 in tir.serial(4):\n",
            "                            with tir.block(\"Y_update\"):\n",
            "                                vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                                vj = tir.axis.spatial(128, j_0 * 4 + j_1)\n",
            "                                vk = tir.axis.reduce(128, k_0 * 8 + k_1)\n",
            "                                tir.reads(Y[vn, vi, vj], A[vn, vi, vk], B[vn, vk, vj])\n",
            "                                tir.writes(Y[vn, vi, vj])\n",
            "                                Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
            "                for ax0 in tir.vectorized(4):\n",
            "                    with tir.block(\"C\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 4 + ax0)\n",
            "                        tir.reads(Y[vn, vi, vj])\n",
            "                        tir.writes(C[vn, vi, vj])\n",
            "                        C[vn, vi, vj] = tir.max(Y[vn, vi, vj], tir.float32(0))\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " @tvm.script.ir_module\n",
        "class TargetModule:\n",
        "    @T.prim_func\n",
        "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
        "        T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
        "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
        "        for i0 in T.parallel(16):\n",
        "            for i1, i2_0 in T.grid(128, 16):\n",
        "                for ax0_init in T.vectorized(8):\n",
        "                    with T.block(\"Y_init\"):\n",
        "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                        j = T.axis.spatial(128, i2_0 * 8 + ax0_init)\n",
        "                        Y[n, i, j] = T.float32(0)\n",
        "                for ax1_0 in T.serial(32):\n",
        "                    for ax1_1 in T.unroll(4):\n",
        "                        for ax0 in T.serial(8):\n",
        "                            with T.block(\"Y_update\"):\n",
        "                                n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                                j = T.axis.spatial(128, i2_0 * 8 + ax0)\n",
        "                                k = T.axis.reduce(128, ax1_0 * 4 + ax1_1)\n",
        "                                Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
        "                for i2_1 in T.vectorized(8):\n",
        "                    with T.block(\"C\"):\n",
        "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                        j = T.axis.spatial(128, i2_0 * 8 + i2_1)\n",
        "                        C[n, i, j] = T.max(Y[n, i, j], T.float32(0))"
      ],
      "metadata": {
        "id": "avPqqjGIwBAB"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and Evaluate"
      ],
      "metadata": {
        "id": "caUw-E3zwIav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "before_rt_lib = tvm.build(MyBmmRelu, target=\"llvm\")\n",
        "after_rt_lib = tvm.build(sch.mod, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "b_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "c_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "after_rt_lib[\"bmm_relu\"](a_tvm, b_tvm, c_tvm)\n",
        "before_timer = before_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
        "print(\"Before transformation:\")\n",
        "print(before_timer(a_tvm, b_tvm, c_tvm))\n",
        "\n",
        "f_timer = after_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
        "print(\"After transformation:\")\n",
        "print(f_timer(a_tvm, b_tvm, c_tvm))"
      ],
      "metadata": {
        "id": "6DxGUidywJRF",
        "outputId": "e938bac5-56ea-416c-d1a9-30ebb6237e21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before transformation:\n",
            "Execution time summary:\n",
            " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
            "  49.4828      49.4828      49.4828      49.4828       0.0000   \n",
            "               \n",
            "After transformation:\n",
            "Execution time summary:\n",
            " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
            "  17.9261      17.9261      17.9261      17.9261       0.0000   \n",
            "               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SmE6nc4883-K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}